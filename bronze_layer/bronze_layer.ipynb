{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e08de235-e204-472a-9925-131516c3a334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Batch Data Ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "078ca0e9-3d0c-4402-9fc1-f5baf8a27978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    " \n",
    "airlines_schema = StructType([\n",
    "    StructField(\"IATA_CODE\", StringType(), True),\n",
    "    StructField(\"AIRLINE\", StringType(), True),\n",
    "    StructField(\"LOAD_TIMESTAMP\", TimestampType(), True)\n",
    "])\n",
    " \n",
    "airports_schema = StructType([\n",
    "    StructField(\"IATA_CODE\", StringType(), True),\n",
    "    StructField(\"AIRPORT\", StringType(), True),\n",
    "    StructField(\"CITY\", StringType(), True),\n",
    "    StructField(\"STATE\", StringType(), True),\n",
    "    StructField(\"COUNTRY\", StringType(), True),\n",
    "    StructField(\"LATITUDE\", StringType(), True),\n",
    "    StructField(\"LONGITUDE\", StringType(), True),\n",
    "    StructField(\"LOAD_TIMESTAMP\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89488407-8392-4c32-96c8-283356e334f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_map = {\n",
    "    \"airlines.csv\": airlines_schema,\n",
    "    \"airports.csv\": airports_schema\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6cdd15e-77f4-47a0-89e5-9f03a1aba456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch file: airlines.csv\nSaved Bronze table: airlines\nProcessing batch file: airports.csv\nSaved Bronze table: airports\nSkipping non-batch file: flights.csv\n"
     ]
    }
   ],
   "source": [
    "raw_path = \"dbfs:/FileStore/tables/sahan_project/raw\"\n",
    "bronze_path = \"dbfs:/FileStore/tables/sahan_project/bronze/batch_data\"\n",
    " \n",
    "# List all files in RAW folder\n",
    "raw_files = dbutils.fs.ls(raw_path)\n",
    " \n",
    "for file in raw_files:\n",
    "    file_name = file.name\n",
    "   \n",
    "    # process only if schema exists for this file\n",
    "    if file_name in schema_map:\n",
    "        print(f\"Processing batch file: {file_name}\")\n",
    "       \n",
    "        # Read with schema\n",
    "        df = (\n",
    "            spark.read\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema_map[file_name])\n",
    "            .csv(f\"{raw_path}/{file_name}\")\n",
    "        )\n",
    " \n",
    "        # Add metadata\n",
    "        from pyspark.sql.functions import current_timestamp, input_file_name\n",
    " \n",
    "        df_bronze = df.withColumn(\"INGESTED_AT\", current_timestamp()) \\\n",
    "                      .withColumn(\"SOURCE_FILE\", input_file_name())\n",
    " \n",
    "        # Save to Bronze\n",
    "        table_name = file_name.replace(\".csv\", \"\")\n",
    " \n",
    "        df_bronze.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "            .save(f\"{bronze_path}/{table_name}\")\n",
    " \n",
    "        print(f\"Saved Bronze table: {table_name}\")\n",
    " \n",
    "    else:\n",
    "        print(f\"Skipping non-batch file: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4994660-78c5-49ad-9a15-5a93046b1d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = spark.read.format(\"delta\") \\\n",
    "    .load(\"dbfs:/FileStore/tables/sahan_project/bronze/batch_data/airlines/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c6b8ca6-d1ff-440f-8b44-364639f8bc1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf905f7c-508f-4abb-92aa-18120c1ef784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Import required types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28091dc-f528-4349-871f-bd079292825b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    IntegerType, StringType, TimestampType\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e6f1be0-a6d1-41a9-b4b8-234ad83f20f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Define flights_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d191629c-dbcb-4fbd-bda9-f3573f79f684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flights_schema = StructType([\n",
    "    StructField(\"YEAR\", IntegerType(), True),\n",
    "    StructField(\"MONTH\", IntegerType(), True),\n",
    "    StructField(\"DAY\", IntegerType(), True),\n",
    "    StructField(\"DAY_OF_WEEK\", IntegerType(), True),\n",
    "    StructField(\"AIRLINE\", StringType(), True),\n",
    "    StructField(\"FLIGHT_NUMBER\", StringType(), True),\n",
    "    StructField(\"TAIL_NUMBER\", StringType(), True),\n",
    "    StructField(\"ORIGIN_AIRPORT\", StringType(), True),\n",
    "    StructField(\"DESTINATION_AIRPORT\", StringType(), True),\n",
    "    StructField(\"SCHEDULED_DEPARTURE\", StringType(), True),\n",
    "    StructField(\"DEPARTURE_TIME\", StringType(), True),\n",
    "    StructField(\"DEPARTURE_DELAY\", StringType(), True),\n",
    "    StructField(\"TAXI_OUT\", StringType(), True),\n",
    "    StructField(\"WHEELS_OFF\", StringType(), True),\n",
    "    StructField(\"SCHEDULED_TIME\", StringType(), True),\n",
    "    StructField(\"ELAPSED_TIME\", StringType(), True),\n",
    "    StructField(\"AIR_TIME\", StringType(), True),\n",
    "    StructField(\"DISTANCE\", IntegerType(), True),\n",
    "    StructField(\"WHEELS_ON\", StringType(), True),\n",
    "    StructField(\"TAXI_IN\", StringType(), True),\n",
    "    StructField(\"SCHEDULED_ARRIVAL\", StringType(), True),\n",
    "    StructField(\"ARRIVAL_TIME\", StringType(), True),\n",
    "    StructField(\"ARRIVAL_DELAY\", StringType(), True),\n",
    "    StructField(\"DIVERTED\", StringType(), True),\n",
    "    StructField(\"CANCELLED\", StringType(), True),\n",
    "    StructField(\"CANCELLATION_REASON\", StringType(), True),\n",
    "    StructField(\"AIR_SYSTEM_DELAY\", StringType(), True),\n",
    "    StructField(\"SECURITY_DELAY\", StringType(), True),\n",
    "    StructField(\"AIRLINE_DELAY\", StringType(), True),\n",
    "    StructField(\"LATE_AIRCRAFT_DELAY\", StringType(), True),\n",
    "    StructField(\"WEATHER_DELAY\", StringType(), True),\n",
    "    StructField(\"LOAD_TIMESTAMP\", TimestampType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb37c03f-1253-4a0f-b3e5-882cece5304e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Bronze Streaming Ingestion (FROM RAW â†’ BRONZE)\n",
    "- Define paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a39bd4f9-a7aa-4cf3-9364-3ff8cb61ed50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_path = \"dbfs:/FileStore/tables/sahan_project/raw\"\n",
    "bronze_path = \"dbfs:/FileStore/tables/sahan_project/bronze/streaming_data\"\n",
    "checkpoint_path = \"dbfs:/FileStore/tables/sahan_project/checkpoint\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8a29fb3-55e9-42b0-b7e5-ddfd819a3b9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check if Bronze table already exists\n",
    "- This is needed for schema validation & evolution control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98bd5975-4a67-4697-92ec-5e61eab7d962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def delta_exists(path):\n",
    "    try:\n",
    "        dbutils.fs.ls(path + \"/_delta_log\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    " \n",
    "bronze_exists = delta_exists(bronze_path)\n",
    "print(\"Bronze Exists:\", bronze_exists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31212220-1cfc-44b1-bb6b-92f99393f40c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Validate schema against existing Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec944eec-01e2-4cf9-ba8b-7e815bd11fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def validate_schema(incoming_schema, existing_schema):\n",
    "    incoming_cols = {f.name: f.dataType for f in incoming_schema.fields}\n",
    "    existing_cols = {f.name: f.dataType for f in existing_schema.fields}\n",
    " \n",
    "    # Columns added later (should not be validated)\n",
    "    ignore_cols = {\"INGESTED_AT\", \"SOURCE_FILE\"}\n",
    " \n",
    "    for col, dtype in existing_cols.items():\n",
    "        if col in ignore_cols:\n",
    "            continue\n",
    "        if col not in incoming_cols:\n",
    "            raise Exception(f\"Missing required column: {col}\")\n",
    "        if incoming_cols[col] != dtype:\n",
    "            raise Exception(f\"Data type mismatch for column: {col}\")\n",
    " \n",
    "    print(\"Schema validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7dc7a71-4fb0-4cee-920c-9a4112c79ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if bronze_exists:\n",
    "    existing_df = spark.read.format(\"delta\").load(bronze_path)\n",
    "    validate_schema(flights_schema, existing_df.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c0e9e08-1a5d-486d-b895-5d1bb6451589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Read RAW data as STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c33d4c-3ce4-4c60-96f5-11b14b89285e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream_df = (\n",
    "    spark.readStream\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(flights_schema)   #  Mandatory\n",
    "    .load(raw_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9518185-c9bd-4aff-b5ba-75166ba79f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Add Bronze metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6a88636-e9bc-40b6-90c0-d640a77dc6bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, input_file_name\n",
    "\n",
    "bronze_stream_df = (\n",
    "    stream_df\n",
    "    .withColumn(\"INGESTED_AT\", current_timestamp())\n",
    "    .withColumn(\"SOURCE_FILE\", input_file_name())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50b9ed48-4db5-4890-9c80-c0beb31b17bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Write to Bronze streaming_data (Delta + Schema Evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26fffd92-ead2-438d-9685-a2e5968fcb04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fbdec25ee10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    bronze_stream_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path)\n",
    "    .option(\"mergeSchema\", \"true\")   # handles new columns safely\n",
    "    .trigger(once=True) # Spark stops itself\n",
    "    .start(bronze_path)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1daa42b6-7fcf-4640-9002-cd36446ed55d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active  # Check active streams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ebf0eee-f0eb-42c2-9419-d48303557fe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Verify data is ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ebd0c46-6657-451a-abdb-585232bc366c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5819415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"delta\") \\\n",
    "    .load(bronze_path) \\\n",
    "    .count()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}